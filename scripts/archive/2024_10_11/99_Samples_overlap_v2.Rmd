---
title: "Initial analysis"
date: "2023-04-12"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: true
    toc_depth: 3
    number_sections: true
    theme: lumen
---

# Background

We have cohort of samples profiled for proteomics, genomics and metylation. We want to create a harmonized clinical file for all these patients.

In regards to proteomics. Samples were profiled ;

1) Psomagen cohort
2) Olink 2023 cohort (Q-13356)
3) Olink 2024 cohort

In addition, some patients were also profiled by genomics (KLK2 SNPs) and methylation.

# Objectives

1. Gather data
2. Clean up clinical data
3. Summary of data

# Pre-processing 

## Loading packages

```{r, message=FALSE, warning=FALSE}
library(here)
library(tidyverse)
library(readxl)   
library(readr)
library(stringr)

library(tidyverse)
library(ggplot2)
library(VennDiagram)
library(ggvenn)
```


## Directories

```{r}
wd <- list()
wd$main <- here()
wd$data <- file.path(wd$main, "data")
wd$manishData <- file.path(wd$data, "raw/data_fromManish")
wd$d2024 <- file.path(wd$data, "updated_2024")
wd$d2024_npx <- file.path(wd$d2024, "NPX_data")
wd$output <- file.path(wd$main, "output")
wd$script <- file.path(wd$main, "scripts")

wd$outData <- file.path(wd$output, "data")
wd$outCurr <- file.path(wd$output, "01_InitialAnalys")

t.testDir <- file.path(wd$outCurr , "t_test")
dir.create(t.testDir)
```


Create directories

```{r}
if (!file.exists(wd$outCurr)) {
  dir.create(wd$outCurr)
} else {
  print("Directory already exists")
}
```

Load functions

```{r}
source(file.path(wd$script, "functions.R"))
```



# Objective 1

**Gather data**

## Psomagen 

There were 2 files provided by Manish, we detail them here and read into R.

1. **E3072_AN00003660_AN00003661_NPX_2022-04-21-columns**

This file is the NPX values from Olink. Samples are listed in the `SampleID` column

```{r}
# Read the files
dat_NPX <- readxl::read_excel(file.path(wd$d2024_npx, "batch_01_E3072_AN00003660_AN00003661_NPX_2022-04-21-columns.xlsx"))
```

2. **Proteomic Project Clinical file 07_23_24_Combined_ID.xlsx**

This contains the clinical files of all Proteomics cohort

```{r}
meta_file <- file.path(file.path(wd$d2024, "clinical_data/Proteomic Project Clinical file 09_10_24_Combined_ID_zaki_edited.xlsx"))
```


### NPX data

Read the NPX data 

**E3072_AN00003660_AN00003661_NPX_2022-04-21-columns**

This file is the NPX values from Olink. 

Get Sample ID (listed in the `SampleID` column)

```{r}
b1_id <- unique(dat_NPX$SampleID)
length(b1_id)
```

There are `length(b1_id)` samples assayed by Olink. This includes "Sample Control" as well, an internal control used by Olink. 

Find the number of samples not including the internal control

```{r}
b1_noCtrl <- b1_id[!grepl("SC", b1_id)]
length(b1_noCtrl)
```

### Clinical data

In the Psomagen cohort, some samples were profiled serially. The excel file contains 2 sheets related the Psomagen cohort, sheets 2 & 3.

Sheet 2 contains only the unique patients IDs per row. It contains all the clinical data, eg - surgery, PSA values, tumor stage, date of death...etc. 


While Sheet 3 have the same number of rows as the NPX data. In sheet 3, the same patient with multiple timepoints is represented in multiple rows. There is a column `sample_id` that links to the NPX `sampleID`. 


```{r}
ps_clin.1 <- read_xlsx(meta_file, sheet = 3)
```

Synonym sample IDs are provided in sheet 4

```{r}
ps_clin.2 <- read_xlsx(meta_file, sheet = 4)
```


## Olink Q-13356 

There were 2 files provided by Manish, we detail them here and read into R.

1. **Q-13356_Kohli_EXTENDED_NPX_2024-03-11**

This file is the NPX values from Olink. Samples are listed in the `SampleID` column


2. The same clinical file as above

This contains the clinical files of Psomagen cohort and Olink Q-13356 cohort


### NPX data

Read the NPX data. Samples are listed in the `SampleID` column

```{r}
# Read the files
dat_NPX2 <- readr::read_delim(file.path(wd$d2024_npx, "batch_02_Q-13356_Kohli_EXTENDED_NPX_2024-03-11.csv"), delim = ";")

dat_NPX2 <- readr::read_delim(file.path(wd$d2024_npx, "Re_delivery_Intensity_based/Q-13356_Data Delivery/Q-13356_Kohli_Intensity_EXTENDED_NPX_2024-10-30.csv"), delim = ";")
```

Get Sample ID

```{r}
b2_id <- unique(dat_NPX2$SampleID)
length(b2_id)
```

There are `r `length(b2_id)` samples assayed by Olink. This includes "Sample Control" as well, an internal control used by Olink. 

Find the number of samples not including the internal control

```{r}
b2_noCtrl <- b2_id[!grepl("CONTROL_SAMPLE|NEG_CTRL|PLATE_CTRL", b2_id)]
length(b2_noCtrl)
```

### Clinical data

In the this Olink Q-13356 cohort, there are no serial samples. Clinical data is contained in sheet 4 & 5. of the excel files.

Sheets 4 & 5 contains contains all the clinical data, eg - surgery, PSA values, tumor stage, date of death...etc. Sheet 4 is limited to the CRPC cohort and sheet 5 is limited to HSPC cohort. There is a column `Sample ID (validation)` that links to the NPX `sampleID`.


```{r}
q_133_clin.1 <- read_xlsx(meta_file, sheet = 4) %>% 
  # Rename columns
  dplyr::rename(sample_id = 'Sample ID (validation)')
n1 <- length(unique(q_133_clin.1$`HCI number`)) 
n1
```

We repeat reading the clinical data of the HSPC cohort

```{r}
q_133_clin.2 <- read_xlsx(meta_file, sheet = 5) %>% 
  # Rename columns
  dplyr::rename(sample_id = 'Sample ID (validation)')
n2 <- length(unique(q_133_clin.2$`HCI Number`)) 
n2
```

Based on the NPX, we have `r length(b2_noCtrl)` samples. Meanwhile in the clinical file, we have `r n1` in CRPC and `r n2` for HSCP. The total in clinical file is `r n1 + n2`.

There is one less patient in the clinical sheet. 

Clarification was given by Claire 

> From: Claire Hanson <Claire.Hanson@hci.utah.edu>   
> Sent: Thursday, June 20, 2024 9:33 AM.  
To: Zaki Wilmot <zaki.wilmot@hci.utah.edu>; Manish Kohli <Manish.Kohli@hci.utah.edu>; Enos Ampaw <Enos.Ampaw@hci.utah.edu>   
> Subject: Re: Overlapping files
> 
> Hi Zaki, 
> 
> The duplicate sample is 34 and 78 (2021-2165). We used sample ID 34 as one of the bridging samples as well. 
> 
>Thanks, 
Claire 

We will keep this in mind when we process the NPX data


## Olink Q-15806

### NPX data

Read the NPX data. Samples are listed in the `SampleID` column

```{r}
# Read the files
dat_NPX3 <- readr::read_delim(file.path(wd$d2024_npx, "Q-15806_Kohli_NPX_2024-07-29.csv"), delim = ";")

dat_NPX3 <- readr::read_delim(file.path(wd$d2024_npx, "Re_delivery_Intensity_based/Q-15806_Data Delivery/Q-15806_Kohli_EXTENDED_NPX_2024-10-30.csv"), delim = ";")
```

Get Sample ID

```{r}
b3_id <- unique(dat_NPX3$SampleID)
length(b3_id)
```

There are `r `length(b3_id)` samples assayed by Olink. This includes "Sample Control" as well, an internal control used by Olink. 

Find the number of samples not including the internal control. This time internal control is given as "NA" in the SampleID.

```{r}
b3_noCtrl <- b3_id[!is.na(b3_id)]
length(b3_noCtrl)
```

We have 88 samples. 

### Clinical data

Two tab of clinical were provided for Olink Q-15806.

The first files details the Olink sampleID and HCI collection id. We read this first, as this is what is currently required

```{r}
q_158_d <- read_xlsx(meta_file, sheet = 8) %>% 
  # Edit column names
  rename(HCI_cID = 'HCI Number',
         sample_id = 'Sample ID',
         Tx_stage = 'Pre/Post Tx?')
```



## Mehtylation data

We obtained methylation data from Liang. In Liang's email to Manish, he mentioned ;

> Hi Manishâ€”I am attaching methylation data matrix with first column as patient IDs and first row as genomic regions (chr_start_end, hg38). Each region is a methylation haplotype block. The content reflects methylation block score (MBS) from each methylation haplotype block. Let me know if additional explanation is needed. Liang

Lets read this data. Note that the IDs here are the HCI collection IDs

```{r}
dat_met <- read_xlsx(file.path(wd$d2024, "methylation/MBS_mHAPclinical.xlsx"))
```



# Objective 2

**Clean up clinical data**

We want to combine all data as one df. To make counting and overlapping easier. The unique IDs to merge across these different platforms will be the HCI ID. For the clinical data with mrn & HCI collection ID, we make them into a data frame. 

The methylation has no MRN file associated, so we leave it for now


```{r}
df1 <- data.frame(
  # MRN
  mrn = c(ps_clin.1$mrn, # Psomagen
          q_133_clin.1$`MRN (UUHSC)`, q_133_clin.2$`MRN (UUHSC)`, # Olink Q-13356
          q_158_d$MRN), # Olink Q-158
  # HCI collection ID
  HCI_cID = c(ps_clin.1$`collection_id-hci_id`,  
              q_133_clin.1$`HCI number`, q_133_clin.2$`HCI Number`,
              q_158_d$HCI_cID)
) %>% 
  # Get unique combinations
  distinct() %>% 
  # Remove leading 0
  mutate(mrn = str_remove(mrn, "^0+")) %>% distinct()
```

Lets determine if all the samples we collected was also profiled by methylation

```{r}
filter(dat_met[,1:5], !Samples %in% df1$HCI_cID)
```

**One** sample was profiled solely by methylation. Lets add this sample

```{r}
meth_samp <- data.frame(
  HCI_cID =dat_met$Samples)

df1 <- df1 %>% full_join(meth_samp) %>% distinct()

```

## Cohort info

Now lets add the cohort metadata. We will combine cohort "C" and cohort "D" as one group "C_D".

> Need to find a simplier way to merge the annotations

```{r}
# For simplicity rename the metadata
m1 <- ps_clin.1
m2.1 <- q_133_clin.1
m2.2 <- q_133_clin.2
m3 <- q_158_d
m4 <- dat_met[,1:3] # Methylation data


df_meta.full <- data.frame(
  mrn = c(m1$mrn,
          m2.1$`MRN (UUHSC)`, m2.2$`MRN (UUHSC)`,
          m3$MRN, 
          rep(NA, each=nrow(m4))),
  # HCI collection ID
  HCI_cID = c(m1$`collection_id-hci_id`,  
              m2.1$`HCI number`, m2.2$`HCI Number`,
              m3$HCI_cID,
              m4$Samples),
  cohort = c(m1$cohort,
             rep("D", nrow(m2.1)), rep("B", nrow(m2.2)),
             m3$Cohort,
             m4$Cohort),
  study = c(rep("Psomagen", each=nrow(m1)),
            rep("Q-13356", each=nrow(m2.1)), rep("Q-13356", each=nrow(m2.2)),
            rep("Q-15806", each=nrow(m3)),
            rep("Meth", each=nrow(m4))),
  serial_sample = 
    c(m1$serial_sample,
      #rep(1, each=nrow(m2.1)), rep(1, each=nrow(m2.2)),
      m2.1$`Biobank Collection #`, m2.2$`Biobank collection #`,
      m3$'Serial Sample #',
      m4$Serial)
) %>%   
  mutate(
    # Change the m3 (Q-13358) biobank info
    serial_sample = gsub("Sample", "", serial_sample),
    serial_sample = gsub("_HCI_Num", "", serial_sample),
    #Change cohort to only A,B,C,D. Keep C & D same
    cohort=case_when(cohort %in% c("B","B*","B**")~"B",
                      cohort%in% c("C", "D","D*")~"C_D",
                      TRUE ~ as.character(cohort))) %>% 
  
  distinct() 

# Some mrn has leading 0, so remove these
df_meta.full <- df_meta.full %>% 
  mutate(mrn = str_remove(mrn, "^0+")) %>% distinct()


write.csv(df_meta.full, file.path(wd$outCurr, "MetaData.csv"))

df_cohort <- df_meta.full %>% 
  select(HCI_cID:cohort) %>% 
  distinct()
  
```

Check if there are multiple cohort calls for a HCI collection ID

```{r}
mm <- 
df_cohort %>% 
  dplyr::group_by(HCI_cID) %>%
  dplyr::summarise(n = dplyr::n(), .groups = "drop") %>%
  dplyr::filter(n > 1L)
```

Lets see what these are

```{r}
dd <- df_meta.full %>% filter(HCI_cID %in% mm$HCI_cID) %>% arrange(HCI_cID)
write.csv(dd, file.path(wd$outCurr, "Mismatch_cohorts.csv"))
```

If we ignore Liang's cohort, do we have any mis-match?

```{r}
mm_tmp <- df_meta.full %>% 
  filter(!study == "Meth") %>% 
  select(HCI_cID:cohort) %>% 
  distinct() %>% 
  dplyr::group_by(HCI_cID) %>%
  dplyr::summarise(n = dplyr::n(), .groups = "drop") %>%
  dplyr::filter(n > 1L)

dd2 <- df_meta.full %>% filter(HCI_cID %in% mm_tmp$HCI_cID) %>% arrange(HCI_cID) %>% filter(!study == "Meth")
dd2
```


According to the conversation with Manish. The most recent updated clinical files are from his group. So in the case of mis-match between the Olink (Manish group) with Liang (Methylation), we will ignore the cohort information given by Liang.

Lets make a master cohort information sheet

```{r}
# Get cohort from Manish study
df_cohort_1 <- df_meta.full %>% 
  filter(study %in% c("Psomagen", "Q-13356", "Q-15806")) %>% 
  select(HCI_cID:cohort) %>% 
  distinct()

# Get cohort from Liang study
# Exclude any cohort information that is contained in Manish
df_cohort_2 <- df_meta.full %>% 
  filter(study %in% c("Meth")) %>% 
  filter(!HCI_cID %in% df_cohort_1$HCI_cID) %>% 
  select(HCI_cID:cohort) %>% 
  distinct()

dd <- rbind(df_cohort_1, df_cohort_2)

# Combine with the information from all patient.
df_cohort_all <- data.frame(
  HCI_cID = unique(df_meta.full$HCI_cID)) %>% 
  left_join(dd) %>% distinct()
```

## Serial sample info

We also noted that serial sample information may be incorrect

```{r}
mm2 <- 
df_meta.full %>% 
  select(HCI_cID, serial_sample) %>% distinct() %>% 
  dplyr::group_by(HCI_cID) %>%
  dplyr::summarise(n = dplyr::n(), .groups = "drop") %>%
  dplyr::filter(n > 1L)
```

Lets see what these are

```{r}
dd <- df_meta.full %>% filter(HCI_cID %in% mm2$HCI_cID) %>% arrange(HCI_cID)
dd
write.csv(dd, file.path(wd$outCurr, "Mismatch_serial_samples.csv"))
```

## Manual fix

We see different cohort assignment for two samples. And mismatch serial for one sample

> Lets manually fix for now

```{r}
df_meta.full <- df_meta.full %>% 
  mutate(cohort = case_when(HCI_cID == "2021-0782" & study == "Q-15806" ~ "C_D",
                            HCI_cID == "2021-2802" & study == "Q-13356" ~ "B",
                            HCI_cID == "2021-2802" & study == "Psomagen" ~ "B",
                            TRUE ~ cohort),
         serial_sample = case_when(HCI_cID == "2021-1149" & study == "Q-13356" ~ "2",
                            TRUE ~ serial_sample))
```

Fix the df_cohort_all as well

```{r}
df_cohort_all <- df_cohort_all %>% 
  mutate(cohort = case_when(
    HCI_cID == "2021-0782" ~ "C_D",
    HCI_cID == "2021-2802" ~ "B",
    TRUE ~ cohort)) %>% 
  distinct()
```


Re check if there is still any mismatch

```{r}
# Cohort mismatch
mm_tmp <- df_meta.full %>% 
  filter(!study == "Meth") %>% 
  select(HCI_cID:cohort) %>% 
  distinct() %>% 
  dplyr::group_by(HCI_cID) %>%
  dplyr::summarise(n = dplyr::n(), .groups = "drop") %>%
  dplyr::filter(n > 1L)
mm_tmp

# Serial mismatch
mm2 <- 
df_meta.full %>% 
  select(HCI_cID, serial_sample) %>% distinct() %>% 
  dplyr::group_by(HCI_cID) %>%
  dplyr::summarise(n = dplyr::n(), .groups = "drop") %>%
  dplyr::filter(n > 1L)
mm2
```

## Txt status

Label treatment

```{r}
# df_meta.full <- df_meta.full %>% 
#   mutate(txt_stat = if_else(HCI_cID %in% serial_sam, "Post", "Pre"))
# 
# 
# mm2 <- 
# df_meta.full %>% 
#   select(HCI_cID, cohort, txt_stat) %>% distinct() %>% 
#   dplyr::group_by(HCI_cID) %>%
#   dplyr::summarise(n = dplyr::n(), .groups = "drop") %>%
#   dplyr::filter(n > 1L)
# mm2
```



## Tally

Lets get a tally of the number of sample in each projects


```{r}
df_tally <- df_meta.full %>% filter(!study == "Meth") 

t1 <- df_tally %>% group_by(study) %>% count()
t2.1 <- df_tally %>% filter(study == "Psomagen") %>% pull(mrn) %>% unique() %>% length()
t2.2 <- df_tally %>% filter(study == "Q-13356") %>% pull(mrn) %>% unique() %>% length()
t2.3 <- df_tally %>% filter(study == "Q-15806") %>% pull(mrn) %>% unique() %>% length()


df_counts <- data.frame(
  study = t1$study,
  Num_unique_samples = t1$n,
  Num_unique_patients = c(t2.1, t2.2, t2.3)
)


result <- df_tally %>%
  group_by(cohort, study) %>%
  summarise(count = n())

cohort_wide <- result %>%
  pivot_wider(names_from = cohort, values_from = count, 
              names_prefix = "num_cohort_", values_fill = 0)

df_counts <- df_counts %>%
  left_join(cohort_wide, by = "study")
```

Get tally across all study

```{r}
# Chat GPT script
# Assuming df is your original dataframe
df <- df_tally
# Assuming df is your original dataframe

# Step 1: Calculate total number of unique patients and total samples per study
study_summary <- df %>%
  group_by(study) %>%
  summarise(
    Num_unique_samples = n(),              # Total samples (rows)
    Num_unique_patients = n_distinct(mrn)  # Total unique patients
  )

# Step 2: Calculate the number of samples per cohort within each study
cohort_counts <- df %>%
  group_by(study, cohort) %>%
  summarise(num_samples = n(), .groups = 'drop') %>%
  pivot_wider(
    names_from = cohort, 
    values_from = num_samples, 
    names_prefix = "num_cohort_", 
    values_fill = 0  # Fill missing values with 0
  )

# Step 3: Merge the cohort counts with the study summary
final_df <- study_summary %>%
  left_join(cohort_counts, by = "study")

# Step 4: Calculate the overall totals (handling duplicates across studies)

# Step 4.1: Calculate overall unique samples (deduplicated across studies)
overall_unique_samples <- df %>%
  distinct(mrn, HCI_cID) %>%  # Ensures samples are counted only once across all studies
  summarise(Num_unique_samples = n()) %>%
  pull(Num_unique_samples)

# Step 4.2: Calculate overall unique patients (deduplicated across studies)
overall_unique_patients <- df %>%
  distinct(mrn) %>%  # Ensures patients are counted only once across all studies
  summarise(Num_unique_patients = n()) %>%
  pull(Num_unique_patients)

# Step 4.3: Calculate the overall cohort counts (deduplicated across studies)
overall_cohort_counts <- df %>%
  distinct(mrn, cohort) %>%  # Ensure patients are counted only once per cohort
  group_by(cohort) %>%
  summarise(num_samples = n()) %>%
  pivot_wider(
    names_from = cohort,
    values_from = num_samples,
    names_prefix = "num_cohort_",
    values_fill = 0
  )

# Step 5: Create the "Overall" row with the deduplicated values
overall_row <- tibble(
  study = "Overall",
  Num_unique_samples = overall_unique_samples,
  Num_unique_patients = overall_unique_patients
) %>%
  bind_cols(overall_cohort_counts)

# Step 6: Bind the overall row to the final dataframe
final_df <- bind_rows(final_df, overall_row)


# Manual way
df_tally %>% filter(cohort == "A") %>% pull(HCI_cID) %>% unique() %>% length()
df_tally %>% filter(cohort == "B") %>% pull(HCI_cID) %>% unique() %>% length()
df_tally %>% filter(cohort == "C_D") %>% pull(HCI_cID) %>% unique() %>% length()

df_tally %>% filter(cohort == "A") %>% pull(mrn) %>% unique() %>% length()
df_tally %>% filter(cohort == "B") %>% pull(mrn) %>% unique() %>% length()
df_tally %>% filter(cohort == "C_D") %>% pull(mrn) %>% unique() %>% length()

#write.csv(final_df, "~/Desktop/tally_of_proteomics.csv")
```

Get patient across time

```{r}
df_tally_tmp <- df_tally %>% 
  select(mrn, HCI_cID, cohort) %>% distinct()

# Step 1: Count observations for each mrn in each cohort
mrn_counts <- df_tally_tmp %>%
  group_by(mrn, cohort) %>%
  summarise(count = n(), .groups = 'drop') %>%
  pivot_wider(names_from = cohort, values_from = count, values_fill = 0)

# Step 2: Rename columns for clarity
colnames(mrn_counts)[-1] <- paste0("is_cohort_", colnames(mrn_counts)[-1])

# Step 3: Calculate the total number of observations across cohorts
mrn_counts <- mrn_counts %>%
  mutate(total_observations = rowSums(select(., starts_with("is_cohort_")), na.rm = TRUE))

```



## Final metadata

Lets make a df of the final metadata information. 

```{r}
# Add mrn to the final data
# If there is missing mrn, lets create an artificial MRN for those

# Samples with mrn
mrn_dat <- filter(df1) %>% filter(!is.na(mrn)) %>% distinct()

# Identify data with no MRN
t1 <- df1 %>% filter(is.na(mrn)) 

# Get numher of samples with missing mrn
mrn_na <- nrow(t1)
# Create new id 
mrn_na_id <- paste0("mrn_", 1:mrn_na)

# Data with mrn
t2 <- mrn_dat %>% filter(!is.na(mrn))

t1 <- t1 %>% 
  mutate(mrn = case_when(is.na(mrn) ~ mrn_na_id,
                         TRUE ~ mrn))
df_meta_f <- rbind(t1, t2) %>% 
  left_join(df_cohort_all)

tmp_meta <- df_meta.full %>% select(HCI_cID, serial_sample) %>% distinct()

df_meta_f <- df_meta_f %>% left_join(tmp_meta) %>% arrange(HCI_cID)
```



### Platfrom

Now we indicate if the samples was profiled by which technology 

```{r}
k1 <- df_meta.full %>% filter(study == "Psomagen")
k2 <- df_meta.full %>% filter(study == "Q-13356")
k3 <- df_meta.full %>% filter(study == "Q-15806")
k4 <- df_meta.full %>% filter(study == "Meth")


df_meta_f <- df_meta_f %>% 
  mutate(isPsom = if_else(HCI_cID %in% k1$HCI_cID, "Y", "N"),
         isQ13356 = if_else(HCI_cID %in% k2$HCI_cID, "Y", "N"),
         isQ15806 = if_else(HCI_cID %in% k3$HCI_cID, "Y", "N"),
         isMeth = if_else(HCI_cID %in% k4$HCI_cID, "Y", "N"))
```


For the proteomics study lets exclude methylation data. We know only 1 sample was solely profiled by methylation

```{r}
df_meta_f <- df_meta_f %>% 
  filter(!mrn == "mrn_1")
```



### Sample IDs

In the NPX files we are given the ID as "sample_ID". Lets link the sample ID of the NPX with the sample ID in the clinical data.


```{r}
# --- Psomagen cohort ---- #
# As all sample ID are numbers. We convert it to numeric. Non-number will give NA
# We stored the Psomagen NPX IDs - b1_noCtrl
d1.1 <- data.frame(
  sample_id_psom = as.numeric(b1_noCtrl)
)
# Extract the HCI collection ID from clinical files
d1.2 <- data.frame(
  HCI_cID = ps_clin.1$`collection_id-hci_id`,
  sample_id_psom = as.numeric(ps_clin.1$sample_id)
)
# Merge the two
d1 <- left_join(d1.1, d1.2)
# Santiy check to ensure all NPX data have clinical data, value needs to be 0
sum(is.na(d1$HCI_cID))


# --- Olink Q-13356 cohort ---- #
# We stored the Q-13356 NPX IDs - b2_noCtrl
d2.1 <- data.frame(
  sample_id_Q13356 = as.numeric(b2_noCtrl)
)
# Extract the HCI collection ID from clinical files
# The clinical file also contained a record of a supposed psomagen ID
d2.2 <- data.frame(
  HCI_cID = c(q_133_clin.1$`HCI number`, q_133_clin.2$`HCI Number`),
  sample_id_Q13356 = as.numeric(c(q_133_clin.1$sample_id, q_133_clin.2$sample_id)),
  sample_id_psom_2 = as.numeric(c(q_133_clin.1$`Sample Id (previous analysis)`, q_133_clin.2$`Sample ID (previous analysis)`))
)
# Merge the two
d2 <- left_join(d2.1, d2.2)
# Santiy check to ensure all NPX data have clinical data, value needs to be 0
sum(is.na(d2$HCI_cID))
```

We noted here that there is one sample missing a clinical ID. We go back to the email from Claire that mentioned the sample "2021-2165" was profiled twice and should have the assigned sample_id : 34 and 78 

```{r}
filter(d2, is.na(HCI_cID))
```

We see sample ID 78 is missing clinical data. So we just exclude sample 78 for now

```{r}
d2 <- d2 %>% 
  filter(!sample_id_Q13356 == 78)
```

Repeat for Q-15806

```{r}
d3 <- q_158_d %>% 
  select(HCI_cID, sample_id) %>% 
  mutate(sample_id = as.numeric(sample_id)) %>% 
  rename(sample_id_Q15806 = sample_id)
```



Finally, combine all sample IDs

```{r}
# Combine all the sample IDs
df_meta_f <- df_meta_f %>% 
  left_join(d1) %>% 
  left_join(d2) %>% 
  left_join(d3)
```

## Serial sample

Lets add a column to say if the sample is pre- or post- treatment

Lets focus on samples that are not considered serial samples. In general the serial samples are labelled as anything aside from 1. With 1 meaning pre-treatment and >1 meaning post-treatment. 

This is not necessary the case. There are some 2 & 3 (under serial_sample column) that could be pre-treatment samples. 

Matt gave us a list of samples that are 2 & 3 that is considered as pre-treatment. We read this file

```{r}
# Psomagen and Q13356 cohort
df_serial_info <- read_xlsx(file.path(wd$data, "updated_2024/clinical_data/To_cross_Check Zaki.xlsx"))
```

Identify the samples that are considered post treatment and exclude these

```{r}
# Identify post treatment sample from Matt's file
serial_sam_matt <- df_serial_info %>% filter(Tx_class == "Post Treatment") %>% pull(HCI_cID)

# Identify post treatment sample from Psomagen cohort, this should all be serial_sample 2/3
serial_sam_psom <- df_meta_f %>% filter(isPsom == "Y" & serial_sample %in% c(2,3)) %>% pull(HCI_cID)

# From the Q15806, we also havea sample sheet from Matt to identify pre- and post- sample
serial_sam_q15806<- q_158_d %>% filter(Tx_stage == "Post") %>% pull(HCI_cID)

# All collection samples
serial_sam <- unique(c(serial_sam_matt, serial_sam_psom, serial_sam_q15806))
```

Label the samples 

```{r}
df_meta_f <- df_meta_f %>% 
  mutate(txt_stat = if_else(HCI_cID %in% serial_sam, "Post", "Pre"))
```






# Plots


Lets plot an overview of the sample

```{r}
# Step 1: Summarize the data (count samples for each cohort and txt_stat combination)
summary_df <- df_meta_f %>%
  group_by(cohort, txt_stat) %>%
  summarise(count = n(), .groups = 'drop')

# Create a new column that combines cohort and txt_stat
summary_df$cohort_txt_stat <- paste(summary_df$cohort, summary_df$txt_stat, sep = "_")

# Custom colors: you can choose shades inspired by Tableau colors
custom_colors <- c(
  "A_Pre" = "#1f77b4", "A_Post" = "#aec7e8",  # Blue shades
  "B_Pre" = "#ff7f0e", "B_Post" = "#ffbb78",  # Orange shades
  "C_D_Pre" = "#2ca02c", "C_D_Post" = "#98df8a"  # Green shades
)


# Updated plot
p1 <- ggplot(summary_df, aes(x = cohort, y = 1, size = count, fill = cohort_txt_stat)) +
  geom_point(shape = 21, color = "black", position=position_dodge(width=0.5)) +  # Create circles with black border
  geom_text(aes(label = count), vjust = 2, size = 5, position=position_dodge(width=0.5)) +  # Add text underneath circles
  scale_size_area(max_size = 15) +  # Adjust circle sizes
  scale_fill_manual(values = custom_colors) +  # Set custom colors
  labs(x = "Cohort", y = "", fill = "Cohort and txt_stat", size = "Sample Count") +  # Label x-axis and legend
  theme_bw() +  # Clean background
  theme(legend.position = "right", axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid = element_blank())
ggsave(p1, file=file.path(wd$outCurr, "Treatment_breakdown.pdf"), height = 5, width = 7)

ggplot(summary_df, aes(x = cohort, y = 1, size = count, fill = txt_stat)) +
  geom_point(shape = 21, color = "black", position=position_dodge(width=0.5)) +  # Create circles with black border
  geom_text(aes(label = count), vjust = 2, size = 5, position=position_dodge(width=0.5)) +  # Add text underneath circles
  scale_size_area(max_size = 15) +  # Adjust circle sizes
  scale_fill_manual(values = c("Pre" = "lightblue", "Post" = "orange")) +  # Set fill colors
  labs(x = "Cohort", y = "", fill = "txt_stat", size = "Sample Count") +  # Label x-axis and legend
  theme_minimal() +  # Clean background
  theme(legend.position = "right", axis.text.y = element_blank(), axis.ticks.y = element_blank(),
        panel.grid = element_blank())
```

Lets plot the distirbution of samples

```{r}
# Plotting some sort of timeline

# mrn_counts

# Identify patients groups ;
# Group 1 - mrn that occurs once
# Group 2_set1 - mrn that occurs twice in same group 
# Group 2_set2 - mrn that occurs once in each of the different group, C-D
# Group 3 - mrn that was profiled 3x


group_1_mrns <- mrn_counts %>% filter(total_observations == 1) %>% pull(mrn)
group_2_mrns <- mrn_counts %>% filter(total_observations == 2)
group_2_cohort_B <- group_2_mrns %>% filter(is_cohort_B == 2) %>% pull(mrn)
group_2_cohort_C <- group_2_mrns %>% filter(is_cohort_C_D == 2) %>% pull(mrn)

group_2_mrns_set2 <- group_2_mrns %>% filter(is_cohort_B == 1 & is_cohort_C_D == 1) %>% pull(mrn)




# -- Group 2-- #
df_group2 <- df_meta_f %>%
  filter(mrn %in% group_2_cohort_B) %>% 
  select(mrn, HCI_cID, cohort, txt_stat) %>% arrange(mrn, cohort, txt_stat)

# Step 1: Create a unique pattern by combining cohort and txt_stat for each mrn
# This creates a pattern for each mrn's cohort-txt_stat combination
df_group2 <- df_group2 %>%
  group_by(mrn) %>%
  arrange(cohort, txt_stat) %>%  # Ensure consistent order
  mutate(pattern = paste(cohort, txt_stat, collapse = "-")) %>%
  ungroup()

# Step 2: Assign groups based on unique patterns
# We create a lookup table where each unique pattern is assigned a group
unique_patterns <- df_group2 %>%
  distinct(pattern) %>%
  mutate(group = paste0("Group 2", LETTERS[row_number()]))


# Step 3: Merge the group information back into the original data
df_group2 <- df_group2 %>%
  left_join(unique_patterns, by = "pattern")
df_group2_tmp <- df_group2 %>% select(mrn, group) %>% distinct()



# Making a function, to avoid repetition
# Define a function that processes a cohort
process_cohort <- function(df_meta_f, cohort_mrns, prefix, start_group) {
  # Step 1: Filter and arrange
  df_cohort <- df_meta_f %>%
    filter(mrn %in% cohort_mrns) %>%
    select(mrn, HCI_cID, cohort, txt_stat) %>%
    arrange(mrn, cohort, txt_stat)
  
  # Step 2: Create the pattern for each mrn
  df_cohort <- df_cohort %>%
    group_by(mrn) %>%
    arrange(cohort, txt_stat) %>%
    mutate(pattern = paste(cohort, txt_stat, collapse = "-")) %>%
    ungroup()
  
  # Step 3: Assign groups based on unique patterns
  unique_patterns <- df_cohort %>%
    distinct(pattern) %>%
    mutate(group = paste0(prefix, LETTERS[start_group + row_number() - 1]))
  
  # Step 4: Merge group information back
  df_cohort <- df_cohort %>%
    left_join(unique_patterns, by = "pattern")
  
  # Return the dataframe and the last group number used
  df_cohort_tmp <- df_cohort %>% select(mrn, group) %>% distinct()
  last_group <- start_group + nrow(unique_patterns) - 1
  
  list(df_cohort_tmp = df_cohort_tmp, last_group = last_group)
}

# Process Group 2B (group_2_cohort_B)
result_B <- process_cohort(df_meta_f, group_2_cohort_B, "Group 2", 1)

# Process Group 2C starting from the next group after Group 2B
result_C <- process_cohort(df_meta_f, group_2_cohort_C, "Group 2", result_B$last_group + 1)

result_CD <- process_cohort(df_meta_f, group_2_mrns_set2, "Group 2", result_C$last_group + 1)

# Combine the results
df_group2_combined <- bind_rows(result_B$df_cohort_tmp, result_C$df_cohort_tmp, result_CD$df_cohort_tmp)


# ---- Group 3 ---- #
# Step 1: Get unique combinations of mrn, cohort, and txt_stat
group_4_mrns <- mrn_counts %>% filter(total_observations == 3) %>% pull(mrn)
df_group4 <- df_meta_f %>%
  filter(mrn %in% group_4_mrns) %>% 
  select(mrn, HCI_cID, cohort, txt_stat) %>% arrange(mrn, cohort, txt_stat)


# data_labeled <- df_group4 %>%
#   group_by(mrn, txt_stat) %>%
#   mutate(txt_stat = ifelse(row_number() == 1, txt_stat, paste0(txt_stat, row_number()))) %>%
#   ungroup()


# Step 1: Create a unique pattern by combining cohort and txt_stat for each mrn
# This creates a pattern for each mrn's cohort-txt_stat combination
df_group4 <- df_group4 %>%
  group_by(mrn) %>%
  arrange(cohort, txt_stat) %>%  # Ensure consistent order
  mutate(pattern = paste(cohort, txt_stat, collapse = "-")) %>%
  ungroup()

# Step 2: Assign groups based on unique patterns
# We create a lookup table where each unique pattern is assigned a group
unique_patterns <- df_group4 %>%
  distinct(pattern) %>%
  mutate(group = paste0("Group 3", LETTERS[row_number()]))


# Step 3: Merge the group information back into the original data
df_group4 <- df_group4 %>%
  left_join(unique_patterns, by = "pattern")
df_group4_tmp <- df_group4 %>% select(mrn, group) %>% distinct()

dat_group <- data.frame(
  mrn = c(group_1_mrns, 
          df_group2_combined$mrn,
          df_group4_tmp$mrn),
  group = c(
    rep("Group 1", each=length(group_1_mrns)),
    df_group2_combined$group,
    df_group4_tmp$group)
)

data <- df_meta_f %>% 
  #select(mrn, HCI_cID, cohort, txt_stat) %>% distinct() %>% 
  left_join(dat_group)

# Label consequtive pre or post
data <- data %>%
  group_by(mrn, txt_stat) %>%
  mutate(txt_stat = ifelse(row_number() == 1, txt_stat, paste0(txt_stat, row_number()))) %>%
  ungroup() %>% 
  mutate(txt_stat = factor(txt_stat, levels=c("Pre", "Pre2", "Post", "Post2")))



data2 <- data %>% group_by(group, cohort, txt_stat) %>% 
  arrange(group) %>% 
  summarize(count = n()) %>% 
  mutate(group = factor(group, levels = (unique(group))))


ggplot(data2, aes(x=cohort, y=group, size=count, fill=txt_stat)) +
  geom_point(shape = 21, color = "black", position=position_dodge(width=0.5)) +  
  geom_text(aes(label = count), vjust = 2, size = 5, position=position_dodge(width=0.5)) +  # Add text underneath circles
  theme_bw() +  # Clean background
  theme(legend.position = "right", panel.grid = element_blank()) +
  geom_text(aes(label = count), vjust = 2, size = 5, position=position_dodge(width=0.5)) +  # Add text underneath circlesNULL
  NULL

# Custom colors
# Create a new column that combines cohort and txt_stat
data2 <- data2 %>% 
  mutate(cohort_txt_stat =paste(cohort, txt_stat, sep = "_"),
         cohort_txt_stat = factor(cohort_txt_stat, levels=unique(cohort_txt_stat))) 

# Custom colors: you can choose shades inspired by Tableau colors
custom_colors <- c(
  "A_Pre" = "#1f77b4", "A_Post" = "#aec7e8",  # Blue shades
  "B_Pre" = "#ff7f0e", "B_Post" = "#ffbb78", "B_Post2" = "#ffbb78", # Orange shades
  "C_D_Pre" = "#2ca02c", "C_D_Pre2" = "#2ca02c", 
  "C_D_Post" = "#98df8a",  "C_D_Post2" = "#98df8a" # Green shades
)

ggplot(data2, aes(x=cohort, y=group, size=count, fill=cohort_txt_stat)) +
  geom_point(shape = 21, color = "black", position=position_dodge(width=0.5)) +  
  geom_text(aes(label = count), vjust = 2, size = 5, position=position_dodge(width=0.5)) +  # Add text underneath circles
  theme_bw() +  # Clean background
  scale_fill_manual(values = custom_colors) +  # Set custom colors 
  theme(legend.position = "right", panel.grid = element_blank()) +
  geom_text(aes(label = count), vjust = 2, size = 5, position=position_dodge(width=0.5)) +  # Add text underneath circlesNULL
  NULL

p2 <- 
ggplot(data2, aes(x=cohort, y=group, size=count, fill=txt_stat)) +
  geom_point(shape = 21, color = "black", position=position_dodge(width=0.5)) +  
  scale_size_area(max_size = 15) +  # Adjust circle sizes
  geom_text(aes(label = count), vjust = 2, size = 5, position=position_dodge(width=0.5)) +  # Add text underneath circles
  theme_bw() +  # Clean background
  scale_fill_manual(values = c("Pre" = "lightblue", "Pre2" = "lightblue", 
                               "Post" = "orange", "Post2"= "orange")) +  # Set fill colors
  theme(legend.position = "right", panel.grid = element_blank()) +
  geom_text(aes(label = count), vjust = 2, size = 5, position=position_dodge(width=0.5)) +  # Add text underneath circlesNULL
  NULL


ggsave(p2, file=file.path(wd$outCurr, "Treatment_grouping_pattern.pdf"), height = 5, width = 12)

write.csv(data, file.path(wd$outCurr, "Treatment_grouping_pattern.csv"))
```




# NOT DONE

Now exclude the serial samples from final analysis

```{r}
dat <- df_meta_f %>%  
  filter(!HCI_cID %in% serial_sam)
```


### Bridging samples

There were some samples used as bridging, ie - run on the Psomagen, Q-13356 and Q-15806. Identify these.

```{r}
id_1 <- k1 %>% pull(HCI_cID) %>% unique()
id_2 <- k2 %>% pull(HCI_cID) %>% unique()
id_3 <- k3 %>% pull(HCI_cID) %>% unique()

int_ids = intersect(intersect(id_1, id_2), id_3)

df_meta_f <- df_meta_f %>% 
  mutate(isBridge = case_when(HCI_cID %in% int_ids ~ "Y",
                              TRUE ~ "N"))
```

Do a quick Venn diagram of the bridging samples

```{r}
overlap <- calculate.overlap(
x <- list("Psomagen"=id_1, 
          "Q-13356"=id_2,
          "Q-15806"=id_3))

ggvenn(
  x, 
  #fill_color = c("#00c2c2", "#0073C2FF", "#0000c2"),
  fill_color = pal.study,
  stroke_size = 0.5, set_name_size = 4
  )
```

Lets try to find duplicated samples

```{r}
df_dupe <- df_meta_f %>% group_by(mrn, serial_sample) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))
```



There are `r length(int_ids)` samples considered "bridging" samples.

### Save

We save the cleaned version of metadata with important information

```{r}
write.csv(df_meta_f, file.path(wd$outCurr, "MetaData_cleaned.csv"))
```

# Differences with Hey Jung previous file

We wanted to summarize the difference between the previous file we have, before it was corrected.

Lets only select the proteomics samples

```{r}
df_compare <- df_meta_f %>% 
  filter(isPsom == "Y" | isQ13356 == "Y") %>% 
  dplyr::select(mrn, HCI_cID, cohort, isPsom, isQ13356, sample_id_psom, sample_id_Q13356)
```



Now lets read in Hyujung previous info.

```{r}
# PSomagen
df_old <- read_xlsx(file.path(wd$data, "raw/data_fromHyejung/2022_02_15_landscape_proteomics_combined_data_LIM_v4.0.xlsx"))
```

Rename the columns

```{r}
df_old <- df_old %>% 
  select('collection_id-hci_id', cohort, sample_id) %>% 
  dplyr::rename(HCI_cID = 'collection_id-hci_id',
         cohort_old = cohort,
         psomagen_id = sample_id) %>% 
    mutate(
    #Change cohort to only A,B,C,D. Keep C & D same
    cohort_old=case_when(cohort_old %in% c("B","B*","B**")~"B",
                      cohort_old %in% c("C", "D","D*") ~"C_D",
                      TRUE ~ as.character(cohort_old)))
```

Join the two

```{r}
df_compare2 <- df_compare %>% left_join(df_old)

write.csv(df_compare2, "~/Desktop/tmp.csv")
```


Repeat for the validation (Q-1335) cohort

```{r}
df_old2 <- read_xlsx(file.path(wd$data, "raw/data_fromHyejung/2022_02_15_landscape_proteomics_combined_data_LIM_v4.0.xlsx"))
```



# Summary

## General numbers

Lets focus on samples that are not considered serial samples. In general the serial samples are labelled as anything aside from 1. With 1 meaning pre-treatment and >1 meaning post-treatment. 

This is not necessary the case. There are some 2 & 3 (under serial_sample column) that could be pre-treatment samples. 

Matt gave us a list of samples that are 2 & 3 that is considered as pre-treatment. We read this file

```{r}
df_serial_info <- read_xlsx(file.path(wd$data, "updated_2024/clinical_data/To_cross_Check Zaki.xlsx"))
```

Identify the samples that are considered post treatment and exclude these

```{r}
# Identify post treatment sample from Matt's file
serial_sam_matt <- df_serial_info %>% filter(Tx_class == "Post Treatment") %>% pull(HCI_cID)

# Identify post treatment sample from Psomagen cohort, this should all be serial_sample 2/3
serial_sam_psom <- df_meta_f %>% filter(isPsom == "Y" & serial_sample %in% c(2,3)) %>% pull(HCI_cID)

# All collection samples
serial_sam <- unique(c(serial_sam_matt, serial_sam_psom))
```


Now exclude the serial samples from final analysis

```{r}
dat <- df_meta_f %>%  
  filter(!HCI_cID %in% serial_sam)
```


```{r}
# Number of unique patients
length(unique(dat$mrn))
```

Lets repeat the overlap for non-serial samples

```{r}
id_1 <- dat %>% filter(isPsom == "Y") %>% pull(HCI_cID) %>% unique()
id_2 <- dat %>% filter(isQ13356 == "Y") %>% pull(HCI_cID) %>% unique()
id_3 <- dat %>% filter(isQ15806 == "Y") %>% pull(HCI_cID) %>% unique()


overlap <- calculate.overlap(
x <- list("Psomagen"=id_1, 
          "Q-13356"=id_2,
          "Q-15806"=id_3))

ggvenn(
  x, 
  #fill_color = c("#00c2c2", "#0073C2FF", "#0000c2"),
  fill_color = pal.study,
  stroke_size = 0.5, set_name_size = 4
  )
```

If we do overlap based on mrn

```{r}
id_prot1 <- dat %>% filter(isPsom == "Y") %>% pull(mrn) %>% unique()
id_prot2 <- dat %>% filter(isQ13356 == "Y") %>% pull(mrn) %>% unique()
id_prot3 <- dat %>% filter(isQ15806 == "Y") %>% pull(mrn) %>% unique()


overlap <- calculate.overlap(
x <- list("Psomagen"=id_prot1, 
          "Q-13356"=id_prot2,
          "Q-15806"=id_prot3))

ggvenn(
  x, 
  fill_color = pal.study,
  stroke_size = 0.5, set_name_size = 4
  )
```


Why the differences?

```{r}
filter(dat, mrn %in% overlap$a6) %>% select(-isMeth, -sample_id_psom_2, -isBridge,
                                            -isPsom, -isQ13356, -isQ15806)
```
### Cohort numbers

Lets get the numbers per cohort

```{r}
# Based on HCI collection ID
df_HCI_cID <- dat %>% select(HCI_cID, cohort) %>% distinct()
table(df_HCI_cID$cohort)

# Based on mrn, prioritzing cohort B or cohort C_D
tmp_dat <- dat %>% select(mrn, cohort) %>% distinct() 
df1 <- tmp_dat %>% filter(cohort == "A") %>% rename(cohort_A = cohort)
df2 <- tmp_dat %>% filter(cohort == "B") %>% rename(cohort_B = cohort)
df3 <- tmp_dat %>% filter(cohort == "C_D") %>% rename(cohort_C_D = cohort)

mrn_all <- c(df1$mrn, df2$mrn, df3$mrn)

df_mrn <- data.frame(mrn = mrn_all)

df_mrn <- left_join(df_mrn, df1) %>% left_join(df2) %>% left_join(df3) %>% distinct() %>% 
  arrange(mrn)

# Total samples
unique(df_mrn$mrn) %>% length()

# Number of cohort A
df_mrn %>% filter(!is.na(cohort_A)) %>% pull(mrn) %>% unique() %>% length()

# Number of cohort B that may also be in C_D
df_mrn %>% filter(!is.na(cohort_B)) %>% pull(mrn) %>% unique() %>% length()

# Number of cohort C_D that may also be in B
df_mrn %>% filter(!is.na(cohort_C_D)) %>% pull(mrn) %>% unique() %>% length()



# Number of cohort B that is not in C_D
df_mrn %>% filter(!is.na(cohort_B) & is.na(cohort_C_D))  %>% unique() %>% length()

# Number of cohort C_D that may also be in B
df_mrn %>% filter(!is.na(cohort_C_D)) %>% nrow()


```



## Overlap of samples

Across the samples profiled by individual technology, do a quick Venn diagram of the overlap by samples

```{r}
# Using HCI collection IDs
id_prot <- dat %>% filter(isPsom == "Y" | isQ13356 == "Y" | isQ15806 == "Y") %>% pull(HCI_cID) %>% unique()
id_methy <- dat %>% filter(isMeth == "Y") %>% pull(HCI_cID) %>% unique()


overlap <- calculate.overlap(
x <- list("Proteomics"=id_prot, 
          "Methylation"=id_methy))

ggvenn(
  x, 
  fill_color = c("#0073C2FF", "#EFC000FF", "#868686FF", "#CD534CFF"),
  stroke_size = 0.5, set_name_size = 4
  )

# Using mrn
id_prot <- dat %>% filter(isPsom == "Y" | isQ13356 == "Y" | isQ15806 == "Y") %>% pull(mrn) %>% unique()
id_methy <- dat %>% filter(isMeth == "Y") %>% pull(mrn) %>% unique()


overlap <- calculate.overlap(
x <- list("Proteomics"=id_prot, 
          "Methylation"=id_methy))

ggvenn(
  x, 
  fill_color = c("#0073C2FF", "#EFC000FF", "#868686FF", "#CD534CFF"),
  stroke_size = 0.5, set_name_size = 4
  )
```




# Save

Save the output

```{r}

```

